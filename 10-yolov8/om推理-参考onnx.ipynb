{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e335dd-4a55-4869-932e-2f5d736d5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import IPython.display\n",
    "from ais_bench.infer.interface import InferSession\n",
    "import onnxruntime as rt\n",
    "from det_utils import letterbox, scale_coords, nms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c929ae7-eaba-4e2f-bb01-8b5efa903da2",
   "metadata": {},
   "source": [
    "## 前处理代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce46c51-e907-4cae-b4f7-f3f11acee2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, size, letterbox_image):\n",
    "    \"\"\"\n",
    "        对输入图像进行resize\n",
    "    Args:\n",
    "        size:目标尺寸\n",
    "        letterbox_image: bool 是否进行letterbox变换\n",
    "    Returns:指定尺寸的图像\n",
    "    \"\"\"\n",
    "    ih, iw, _ = image.shape\n",
    "    print(ih, iw)\n",
    "    h, w = size\n",
    "    # letterbox_image = False\n",
    "    if letterbox_image:\n",
    "        scale = min(w/iw, h/ih)\n",
    "        nw = int(iw*scale)\n",
    "        nh = int(ih*scale)\n",
    "        image = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_LINEAR)\n",
    "        # cv2.imshow(\"img\", img)\n",
    "        # cv2.waitKey()\n",
    "        # print(image.shape)\n",
    "        # 生成画布\n",
    "        image_back = np.ones((h, w, 3), dtype=np.uint8) * 128\n",
    "        # 将image放在画布中心区域-letterbox\n",
    "        image_back[(h-nh)//2: (h-nh)//2 + nh, (w-nw)//2:(w-nw)//2+nw , :] = image\n",
    "    else:\n",
    "        image_back = image\n",
    "        # cv2.imshow(\"img\", image_back)\n",
    "        # cv2.waitKey()\n",
    "    return image_back  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2281b82c-6694-468b-a0d2-506631680398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2input(img):\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = img/255\n",
    "    return np.expand_dims(img, axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8fea07-528f-4e35-b8a5-97a7e0b1bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh2xyxy(*box):\n",
    "    \"\"\"\n",
    "    将xywh转换为左上角点和左下角点\n",
    "    Args:\n",
    "        box:\n",
    "    Returns: x1y1x2y2\n",
    "    \"\"\"\n",
    "    ret = [box[0] - box[2] // 2, box[1] - box[3] // 2, \\\n",
    "          box[0] + box[2] // 2, box[1] + box[3] // 2]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad3ab75-0425-45ba-80e3-65be340020b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cod_trf(result, pre, after):\n",
    "    \"\"\"\n",
    "    因为预测框是在经过letterbox后的图像上做预测所以需要将预测框的坐标映射回原图像上\n",
    "    Args:\n",
    "        result:  [x,y,w,h,conf(最大类别概率), x1,y1,conf1, x2,y2,conf2, ..., x21,y21,conf21]\n",
    "        pre:    原尺寸图像\n",
    "        after:  经过letterbox处理后的图像\n",
    "    Returns: 坐标变换后的结果,\n",
    "    \"\"\"\n",
    "    res = np.array(result)\n",
    "    # 提取预测框的坐标和置信度\n",
    "    x, y, w, h, conf = res[:5]\n",
    "    # 提取关键点的坐标和置信度\n",
    "    keypoints = res[5:].reshape(-1, 3)\n",
    "    \n",
    "    # 将[x, y, w, h]转换为[x1, y1, x2, y2]\n",
    "    x1, y1, x2, y2 = xywh2xyxy(x, y, w, h)\n",
    "    \n",
    "    # 获取原图像和经过letterbox处理后的图像的尺寸\n",
    "    h_pre, w_pre, _ = pre.shape\n",
    "    h_after, w_after, _ = after.shape\n",
    "    \n",
    "    # 计算缩放比例和平移量\n",
    "    scale = max(w_pre/w_after, h_pre/h_after)\n",
    "    h_pre, w_pre = h_pre/scale, w_pre/scale\n",
    "    x_move, y_move = abs(w_pre-w_after)//2, abs(h_pre-h_after)//2\n",
    "    \n",
    "    # 变换预测框的坐标\n",
    "    ret_x1, ret_x2 = (x1 - x_move) * scale, (x2 - x_move) * scale\n",
    "    ret_y1, ret_y2 = (y1 - y_move) * scale, (y2 - y_move) * scale\n",
    "    ret_box = [int(ret_x1), int(ret_y1), int(ret_x2), int(ret_y2), conf]\n",
    "    \n",
    "    # 变换关键点的坐标\n",
    "    ret_keypoints = []\n",
    "    for kp in keypoints:\n",
    "        kp_x, kp_y, kp_conf = kp\n",
    "        ret_kp_x = (kp_x - x_move) * scale\n",
    "        ret_kp_y = (kp_y - y_move) * scale\n",
    "        ret_keypoints.extend([int(ret_kp_x), int(ret_kp_y), kp_conf])\n",
    "    \n",
    "    # 组合预测框和关键点的结果\n",
    "    ret = np.array(ret_box + ret_keypoints)\n",
    "    return ret\n",
    "\n",
    "# 假设 pre 和 after 是已经定义的图像\n",
    "# highest_conf_pred = np.array(...)  # 您的68维numpy数组\n",
    "# transformed_result = cod_trf(highest_conf_pred, pre, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2d7ad6-d1d4-4303-ada5-29b8e8d722bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(res, image, color):\n",
    "    \"\"\"\n",
    "    将预测框和关键点绘制在image上\n",
    "    Args:\n",
    "        res: 预测框数据\n",
    "        image: 原图\n",
    "    Returns:\n",
    "        image: 绘制了预测框和关键点的图像\n",
    "    \"\"\"\n",
    "    # 假设 res 的结构是 [x1, y1, x2, y2, conf, x1_kp, y1_kp, conf1_kp, ..., x21_kp, y21_kp, conf21_kp]\n",
    "    # 其中前五个元素是预测框的坐标和置信度，后面是21个关键点的坐标和置信度\n",
    "    \n",
    "    # 提取预测框的坐标和置信度\n",
    "    x1, y1, x2, y2, conf = res[:5]\n",
    "    \n",
    "    if conf < Conf_threshold:\n",
    "        return image\n",
    "    # 画框 后两个参数：颜色和线宽\n",
    "    image = cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 5)\n",
    "    \n",
    "    # 计算预测框的长宽\n",
    "    h, w = int(y2) - int(y1), int(x2) - int(x1)\n",
    "    \n",
    "    # 计算字体大小（随框大小调整）\n",
    "\n",
    "    \n",
    "    # 绘制文本（这里我们使用分数作为文本，因为没有类别名称）\n",
    "    text = \"{:.2f}\".format(float(conf))\n",
    "    \n",
    "    # 绘制文本\n",
    "    image = cv2.putText(image, text, (max(10, int(x1)), max(10, int(y1) - 5)), cv2.FONT_HERSHEY_COMPLEX, Rec_fontsize, (0, 255, 0), Rec_thickness)  # 绿色文本\n",
    "    \n",
    "    # 提取关键点的坐标和置信度\n",
    "    keypoints = res[5:].reshape(-1, 3)\n",
    "    \n",
    "    # 绘制关键点\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        kp_x, kp_y, kp_conf = kp\n",
    "        # color\n",
    "        kpt_color = color[i]['color']\n",
    "        # 画关键点：图片、XY坐标、半径、颜色、线宽（-1为填充）\n",
    "        image = cv2.circle(image, (int(kp_x), int(kp_y)), 5, kpt_color, -1)\n",
    "        \n",
    "        # 标注关键点编号 字体大小 字体颜色 线宽\n",
    "        image = cv2.putText(image, str(i), (int(kp_x) + 5, int(kp_y) + 5), cv2.FONT_HERSHEY_SIMPLEX, Kpt_fontsize, kpt_color, Kpt_thickness)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# 假设 bbox_res 是经过 cod_trf 函数处理后的数据\n",
    "# img = cv2.imread('DSC_5384.jpg')\n",
    "# drawn_image = draw(bbox_res, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b77e28e-8280-42e5-bcc0-d97d02e29e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关键点的名称，id，颜色\n",
    "keypoint_info = {\n",
    "    0: {'name': '肾上腺', 'id': 0, 'color': [101, 205, 228]},\n",
    "    1: {'name': '耳尖', 'id': 1, 'color': [240, 128, 128]},\n",
    "    2: {'name': '胃', 'id': 2, 'color': [154, 205, 50]},\n",
    "    3: {'name': '眼', 'id': 3, 'color': [34, 139, 34]},\n",
    "    4: {'name': '口', 'id': 4, 'color': [139, 0, 0]},\n",
    "    5: {'name': '肝', 'id': 5, 'color': [255, 165, 0]},\n",
    "    6: {'name': '对屏尖', 'id': 6, 'color': [255, 0, 255]},\n",
    "    7: {'name': '心', 'id': 7, 'color': [255, 255, 0]},\n",
    "    8: {'name': '肺', 'id': 8, 'color': [29, 123,243]},\n",
    "    9: {'name': '肺2', 'id': 9, 'color': [0, 255, 255]},\n",
    "    10: {'name': '膀胱', 'id': 10, 'color': [128, 0, 128]},\n",
    "    11: {'name': '脾', 'id': 11, 'color': [74, 181, 57]},\n",
    "    12: {'name': '角窝中', 'id': 12, 'color': [165, 42, 42]},\n",
    "    13: {'name': '神门', 'id': 13, 'color': [128, 128, 0]},\n",
    "    14: {'name': '肾', 'id': 14, 'color': [255, 0, 0]},\n",
    "    15: {'name': '耳门', 'id': 15, 'color': [34, 139, 34]},\n",
    "    16: {'name': '听宫', 'id': 16, 'color': [255, 129, 0]},\n",
    "    17: {'name': '听会', 'id': 17, 'color': [70, 130, 180]},\n",
    "    18: {'name': '肩', 'id': 18, 'color': [63, 103,165]},\n",
    "    19: {'name': '扁桃体', 'id': 19, 'color': [66, 77, 229]},\n",
    "    20: {'name': '腰骶椎', 'id': 20, 'color': [255, 105, 180]}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af0912f-10e8-4a27-897b-252db034c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制FPS参数\n",
    "\n",
    "# FPS的坐标位置（左上角）\n",
    "FPS_offset = (25, 60)\n",
    "\n",
    "# FPS的字体大小\n",
    "FPS_fontsize = 3\n",
    "\n",
    "# FPS的线宽\n",
    "FPS_thickness = 3\n",
    "\n",
    "# FPS的颜色\n",
    "FPS_color = (255, 0, 255)\n",
    "\n",
    "# 绘制检测框参数\n",
    "\n",
    "Rec_fontsize = 3\n",
    "\n",
    "Rec_thickness = 3\n",
    "\n",
    "\n",
    "# 绘制关键点参数\n",
    "\n",
    "Kpt_fontsize = 3\n",
    "\n",
    "Kpt_thickness = 3\n",
    "\n",
    "# 检测置信度（设置置信度阈值，如果检测出来的框的置信度低于该阈值，则不显示）\n",
    "\n",
    "Conf_threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a7c6c-00c7-4f3e-b209-e1d0a993a919",
   "metadata": {},
   "source": [
    "## 推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec943586-93e3-4767-9fd6-c6bf338367c8",
   "metadata": {},
   "source": [
    "### 图像加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4733e441-5a32-47a7-9933-a4c050cd5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('DSC_5384.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeca1af7-5f0f-49a5-b528-83e1b0c184f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3712 5568\n"
     ]
    }
   ],
   "source": [
    "# 图片resize\n",
    "img_after = resize_image(image, (640, 640), True)\n",
    "\n",
    "# 将图像处理成输入的格式\n",
    "data = img2input(img_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1820954-d717-44f3-b4ce-c72195644670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 640, 640)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06de0c7-127b-43bd-a198-476218a5d8e3",
   "metadata": {},
   "source": [
    "### 1.onnx推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d98c595e-125f-475c-a4ba-2f1291f1ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_onnx = 'best.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70227ef2-95e3-4639-a56a-1912f6ecff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2024-05-21 14:31:12.694566425 [E:onnxruntime:Default, env.cc:228 ThreadMain] pthread_setaffinity_np failed for thread: 15083, index: 2, mask: {3, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# 输入模型\n",
    "model_onnx = rt.InferenceSession('best.onnx')  # yolov8模型onnx格式\n",
    "input_name = model_onnx.get_inputs()[0].name\n",
    "label_name = model_onnx.get_outputs()[0].name\n",
    "output_onnx = model_onnx.run([label_name], {input_name: data})[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e42fb36c-e46f-4962-8185-ab416b888136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 640, 640]\n"
     ]
    }
   ],
   "source": [
    "input_format_onnx = model_onnx.get_inputs()[0].shape\n",
    "print(input_format_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ca6a387-351f-4a1d-9449-8bee4279d910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 68, 8400)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_onnx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec5722fd-27f1-4a3c-860e-e9252628e653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 68)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将模型输出调整为 (8400, 68) 形状，以便于处理\n",
    "output_onnx_2 = output_onnx.squeeze().transpose((1, 0))\n",
    "output_onnx_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4493f1ee-ad06-4d38-8108-3e141593603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidences_onnx = output_onnx_2[:, 4]\n",
    "max_conf_index_onnx = np.argmax(confidences_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c732cc97-9bcb-4d29-ad16-8a329754a83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8191"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_conf_index_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4841683-6ee2-410b-b5d5-d0db5d88d22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_conf_pred_onnx = output_onnx_2[max_conf_index_onnx]\n",
    "highest_conf_pred_onnx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191838d",
   "metadata": {},
   "source": [
    "推理结果解读：highest_conf_pred_onnx是长为68的一维数组，其中前5个数据是框的坐标及置信度：(x1, y1) (x2, y2) conf  \n",
    "后63个输入是21*3(21个关键点，每个关键点都是(x, y, conf)的形式)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d24e1c4-3434-44a9-bf42-ec5c7a937243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([358.81714   , 304.8056    , 164.8894    , 281.01233   ,\n",
       "         0.9364102 , 308.37076   , 334.44568   ,   0.9648454 ,\n",
       "       357.027     , 187.1751    ,   0.8896568 , 359.2514    ,\n",
       "       308.93823   ,   0.98701835, 326.8548    , 391.9261    ,\n",
       "         0.926921  , 320.68762   , 303.62936   ,   0.98595   ,\n",
       "       365.13074   , 294.82727   ,   0.9863063 , 338.59222   ,\n",
       "       344.29416   ,   0.9753784 , 330.05737   , 336.07306   ,\n",
       "         0.98130774, 343.1875    , 332.04938   ,   0.98469883,\n",
       "       327.50018   , 347.45752   ,   0.9713981 , 324.77847   ,\n",
       "       260.68372   ,   0.9726881 , 365.33713   , 323.09622   ,\n",
       "         0.9831027 , 331.59705   , 237.72813   ,   0.9545015 ,\n",
       "       347.08047   , 238.52997   ,   0.9551488 , 335.76587   ,\n",
       "       272.6271    ,   0.98179895, 285.73486   , 279.4752    ,\n",
       "         0.9445071 , 279.20816   , 334.70853   ,   0.93409157,\n",
       "       279.62207   , 391.72958   ,   0.8845742 , 388.25107   ,\n",
       "       326.4947    ,   0.96180403, 326.2549    , 411.81134   ,\n",
       "         0.9033017 , 365.7648    , 261.7271    ,   0.9717195 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_conf_pred_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d181b-7230-4550-8ede-3237c698249a",
   "metadata": {},
   "source": [
    "### 2.om推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eff0938-57ca-4ff3-8a35-5769b00295b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_om = 'yolov8n-2.om'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d847cab-966a-42f9-a618-cd1af573ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_om = InferSession(0, model_path_om)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09b6bcbc-ac36-4873-8325-65494670f24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_om.get_inputs()[0].format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b5aa5c4-e4d6-476d-bf5e-8c82f7a46a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_om = model_om.infer(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adc13198-ec6c-4c3b-abee-5b7ab6579c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 68, 8400)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_om.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b7719b7-08e5-4c2d-986e-1991aeae464b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 68)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将模型输出调整为 (8400, 68) 形状，以便于处理\n",
    "output_om_2 = output_om.squeeze().transpose((1, 0))\n",
    "output_om_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "581e6bb0-2c2e-4513-bd45-e4e56bf9c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidences_om = output_om_2[:, 4]\n",
    "max_conf_index_om = np.argmax(confidences_om)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d3004a7-ec2d-48d3-bc31-dd6e35456d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8180"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_conf_index_om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e77a5c8-8048-4247-816e-8ffd36f51f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_conf_pred_om = output_om_2[max_conf_index_om]\n",
    "highest_conf_pred_om.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49503cbc-04c0-4038-8fa3-f22e54f6cb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.87187500e+01,  3.23500000e+02,  3.71875000e+01,  5.93000000e+02,\n",
       "        1.64222717e-03, -1.13750000e+01,  3.68500000e+02,  2.78930664e-02,\n",
       "        6.61328125e+00,  1.90625000e+02,  3.82385254e-02, -1.00625000e+01,\n",
       "        3.25000000e+02,  1.01699829e-02, -1.30312500e+01,  4.29000000e+02,\n",
       "        2.90222168e-02, -1.23359375e+01,  3.32250000e+02,  1.16882324e-02,\n",
       "       -7.11328125e+00,  3.05000000e+02,  1.10778809e-02, -1.30156250e+01,\n",
       "        3.71500000e+02,  9.15527344e-03, -1.41015625e+01,  3.63750000e+02,\n",
       "        7.87353516e-03, -1.31093750e+01,  3.60250000e+02,  6.77490234e-03,\n",
       "       -1.67500000e+01,  3.76750000e+02,  1.04446411e-02, -5.21093750e+00,\n",
       "        2.79250000e+02,  1.76391602e-02, -1.06406250e+01,  3.39500000e+02,\n",
       "        1.20544434e-02, -1.00312500e+01,  2.44375000e+02,  2.31933594e-02,\n",
       "        1.83593750e+00,  2.38750000e+02,  2.37731934e-02, -8.71875000e+00,\n",
       "        2.82750000e+02,  1.14135742e-02,  5.19921875e+00,  2.97000000e+02,\n",
       "        7.25097656e-02,  3.02929688e+00,  3.70500000e+02,  5.81054688e-02,\n",
       "        2.42773438e+00,  4.48000000e+02,  7.42187500e-02,  2.54882812e+00,\n",
       "        3.46250000e+02,  4.71801758e-02, -1.50234375e+01,  4.53500000e+02,\n",
       "        2.78930664e-02, -5.36718750e+00,  2.64250000e+02,  1.75781250e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_conf_pred_om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d2f1a-0920-4e7b-8476-ce9168000159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
